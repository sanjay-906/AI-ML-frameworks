{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 https://github.com/Unity-Technologies/ml-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5XoYAnbot3a",
        "outputId": "9362d50e-7f83-4f58-ede0-ac0c282b05e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ml-agents'...\n",
            "remote: Enumerating objects: 2397, done.\u001b[K\n",
            "remote: Counting objects: 100% (2397/2397), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1924/1924), done.\u001b[K\n",
            "remote: Total 2397 (delta 913), reused 1183 (delta 454), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (2397/2397), 97.66 MiB | 17.72 MiB/s, done.\n",
            "Resolving deltas: 100% (913/913), done.\n",
            "Updating files: 100% (2229/2229), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nNQQoQyXlQet",
        "outputId": "816abc65-16de-48b7-8230-3eee0d044b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.8).\n",
            "python3.10 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.11   2         auto mode\n",
            "  1            /usr/bin/python3.10   1         manual mode\n",
            "  2            /usr/bin/python3.11   2         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 1\n",
            "update-alternatives: using /usr/bin/python3.10 to provide /usr/bin/python3 (python3) in manual mode\n",
            "Python 3.10.12\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,968 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.2 [340 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.5 [1,306 kB]\n",
            "Fetched 1,677 kB in 2s (735 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.5_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "/content/ml-agents\n",
            "Obtaining file:///content/ml-agents/ml-agents-envs\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Pillow>=4.2.1\n",
            "  Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Collecting filelock>=3.4.0\n",
            "  Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Collecting grpcio<=1.48.2,>=1.11.0\n",
            "  Downloading grpcio-1.48.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gym>=0.21.0\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 KB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy<1.24.0,>=1.23.5\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pettingzoo==1.15.0\n",
            "  Downloading PettingZoo-1.15.0.tar.gz (756 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.7/756.7 KB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf<3.21,>=3.6\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml>=3.1.0\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 KB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/lib/python3/dist-packages (from grpcio<=1.48.2,>=1.11.0->mlagents-envs==1.2.0.dev0) (1.16.0)\n",
            "Collecting gym-notices>=0.0.4\n",
            "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
            "Building wheels for collected packages: pettingzoo, gym\n",
            "  Building wheel for pettingzoo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pettingzoo: filename=PettingZoo-1.15.0-py3-none-any.whl size=875659 sha256=a95a066b32b103cdcaf7d66c27d39fc909bb07bbd08047569a6018c1a6479eb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/35/ac/76984cb1c12902d190c818d57c43d25c3f9281591a640ccd13\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827646 sha256=3c27dc42254ac3777ffb2cbd43cfe6d4cdd3d9bcd7e10a00f59ec9f64a0ffc2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "Successfully built pettingzoo gym\n",
            "Installing collected packages: gym-notices, pyyaml, protobuf, Pillow, numpy, grpcio, filelock, cloudpickle, gym, pettingzoo, mlagents-envs\n",
            "  Running setup.py develop for mlagents-envs\n",
            "Successfully installed Pillow-11.1.0 cloudpickle-3.1.1 filelock-3.17.0 grpcio-1.48.2 gym-0.26.2 gym-notices-0.0.8 mlagents-envs numpy-1.23.5 pettingzoo-1.15.0 protobuf-3.20.3 pyyaml-6.0.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "89b69e1b16584ab990ded6683333d555"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/ml-agents/ml-agents\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.2.0.dev0) (11.1.0)\n",
            "Collecting attrs>=19.3.0\n",
            "  Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<=1.48.2,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.2.0.dev0) (1.48.2)\n",
            "Collecting h5py>=2.9.0\n",
            "  Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub>=0.14\n",
            "  Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.1/464.1 KB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mlagents_envs==1.2.0.dev0 in ./ml-agents-envs (from mlagents==1.2.0.dev0) (1.2.0.dev0)\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.2.0.dev0) (1.23.5)\n",
            "Collecting onnx==1.15.0\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.21,>=3.6 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.2.0.dev0) (3.20.3)\n",
            "Requirement already satisfied: pyyaml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from mlagents==1.2.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: six>=1.16 in /usr/lib/python3/dist-packages (from mlagents==1.2.0.dev0) (1.16.0)\n",
            "Collecting tensorboard>=2.14\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch>=2.1.1\n",
            "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cattrs<1.7,>=1.1.0\n",
            "  Downloading cattrs-1.5.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from mlagents_envs==1.2.0.dev0->mlagents==1.2.0.dev0) (3.1.1)\n",
            "Requirement already satisfied: filelock>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mlagents_envs==1.2.0.dev0->mlagents==1.2.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: gym>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from mlagents_envs==1.2.0.dev0->mlagents==1.2.0.dev0) (0.26.2)\n",
            "Requirement already satisfied: pettingzoo==1.15.0 in /usr/local/lib/python3.10/dist-packages (from mlagents_envs==1.2.0.dev0->mlagents==1.2.0.dev0) (1.15.0)\n",
            "Collecting tqdm>=4.42.1\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.9\n",
            "  Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.5.0\n",
            "  Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 KB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=3.7.4.3\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 KB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=0.4\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard>=2.14->mlagents==1.2.0.dev0) (59.6.0)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.2\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 KB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy==1.13.1\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.2.0\n",
            "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/134.6 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.21.0->mlagents_envs==1.2.0.dev0->mlagents==1.2.0.dev0) (0.0.8)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.1/146.1 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 KB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, urllib3, typing-extensions, tqdm, tensorboard-data-server, sympy, packaging, onnx, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, markdown, idna, h5py, fsspec, charset-normalizer, certifi, attrs, absl-py, werkzeug, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, cattrs, tensorboard, nvidia-cusolver-cu12, huggingface_hub, torch, mlagents\n",
            "  Running setup.py develop for mlagents\n",
            "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 attrs-25.1.0 cattrs-1.5.0 certifi-2025.1.31 charset-normalizer-3.4.1 fsspec-2025.2.0 h5py-3.12.1 huggingface_hub-0.28.1 idna-3.10 jinja2-3.1.5 markdown-3.7 mlagents mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 onnx-1.15.0 packaging-24.2 requests-2.32.3 sympy-1.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 torch-2.6.0 tqdm-4.67.1 triton-3.2.0 typing-extensions-4.12.2 urllib3-2.3.0 werkzeug-3.1.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi"
                ]
              },
              "id": "d1d0ac7e2ad54045bf3ac86a903356ba"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!python --version\n",
        "!sudo apt-get install python3.10\n",
        "!sudo update-alternatives --config python3\n",
        "!python --version\n",
        "!sudo apt install python3-pip\n",
        "%cd ml-agents\n",
        "!pip3 install -e ./ml-agents-envs\n",
        "!pip3 install -e ./ml-agents\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vlr-rNKjq9Wr",
        "outputId": "760be015-2b8a-401c-ef4b-343d9b22de1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ml-agents'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, we create training-envs-executables and linux\n",
        "!mkdir ./training-envs-executables\n",
        "!mkdir ./training-envs-executables/linux"
      ],
      "metadata": {
        "id": "IlYyujido5uV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download soccertows and put it in the above path"
      ],
      "metadata": {
        "id": "jzNjIfmgp6Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/SoccerTwoslinux.zip"
      ],
      "metadata": {
        "id": "C2XwRoP9qC2N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod -R 755 ./training-envs-executables/linux/"
      ],
      "metadata": {
        "id": "KAyh-6Auriuj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-Qz7iiOqtGPx",
        "outputId": "6389301f-65e0-4192-c31b-f8fe606d56cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ml-agents'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-learn /content/ml-agents/config/poca/SoccerTwos.yaml --env=/content/ml-agents/training-envs-executables/linux/SoccerTwos.x86_64 --run-id=\"SoccerTwos1\" --no-graphics --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2cT9ZQPsEP8",
        "outputId": "6d438ba2-d0f9-43fa-991f-e9842676c593"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            ┐  ╖\n",
            "        ╓╖╬│╡  ││╬╖╖\n",
            "    ╓╖╬│││││┘  ╬│││││╬╖\n",
            " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
            " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
            " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
            " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
            " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
            " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
            " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
            "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
            "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
            "          ╙╬╬╬╣╣╣╜\n",
            "             ╙\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 1.2.0.dev0,\n",
            "  ml-agents-envs: 1.2.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 2.6.0+cu124\n",
            "[INFO] Connected to Unity environment with package version 2.3.0-exp.3 and communication version 1.5.0\n",
            "[INFO] Connected new brain: SoccerTwos?team=1\n",
            "[INFO] Connected new brain: SoccerTwos?team=0\n",
            "[INFO] Hyperparameters for behavior name SoccerTwos: \n",
            "\ttrainer_type:\tpoca\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t2048\n",
            "\t  buffer_size:\t20480\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  learning_rate_schedule:\tconstant\n",
            "\t  beta_schedule:\tconstant\n",
            "\t  epsilon_schedule:\tconstant\n",
            "\tcheckpoint_interval:\t500000\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t2\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t5\n",
            "\teven_checkpoints:\tFalse\n",
            "\tmax_steps:\t10000000\n",
            "\ttime_horizon:\t1000\n",
            "\tsummary_freq:\t10000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\t\n",
            "\t  save_steps:\t50000\n",
            "\t  team_change:\t200000\n",
            "\t  swap_steps:\t2000\n",
            "\t  window:\t10\n",
            "\t  play_against_latest_model_ratio:\t0.5\n",
            "\t  initial_elo:\t1200.0\n",
            "\tbehavioral_cloning:\tNone\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:104: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3725.)\n",
            "  return func(*args, **kwargs)\n",
            "[INFO] SoccerTwos. Step: 10000. Time Elapsed: 33.774 s. Mean Reward: 0.000. Mean Group Reward: -0.112. Training. ELO: 1200.497.\n",
            "[INFO] SoccerTwos. Step: 20000. Time Elapsed: 64.538 s. Mean Reward: 0.000. Mean Group Reward: -0.308. Training. ELO: 1199.994.\n",
            "[INFO] SoccerTwos. Step: 30000. Time Elapsed: 75.917 s. Mean Reward: 0.000. Mean Group Reward: -0.273. Training. ELO: 1198.748.\n",
            "[INFO] SoccerTwos. Step: 40000. Time Elapsed: 103.254 s. Mean Reward: 0.000. Mean Group Reward: -0.417. Training. ELO: 1197.139.\n",
            "[INFO] SoccerTwos. Step: 50000. Time Elapsed: 131.738 s. Mean Reward: 0.000. Mean Group Reward: -0.158. Training. ELO: 1195.691.\n",
            "[INFO] SoccerTwos. Step: 60000. Time Elapsed: 143.892 s. Mean Reward: 0.000. Mean Group Reward: -0.364. Training. ELO: 1194.360.\n",
            "[INFO] SoccerTwos. Step: 70000. Time Elapsed: 167.137 s. Mean Reward: 0.000. Mean Group Reward: 0.036. Training. ELO: 1193.966.\n",
            "[INFO] SoccerTwos. Step: 80000. Time Elapsed: 195.018 s. Mean Reward: 0.000. Mean Group Reward: -0.050. Training. ELO: 1194.400.\n",
            "[INFO] SoccerTwos. Step: 90000. Time Elapsed: 210.347 s. Mean Reward: 0.000. Mean Group Reward: -0.148. Training. ELO: 1193.237.\n",
            "[INFO] SoccerTwos. Step: 100000. Time Elapsed: 242.316 s. Mean Reward: 0.000. Mean Group Reward: -0.089. Training. ELO: 1193.662.\n",
            "[INFO] SoccerTwos. Step: 110000. Time Elapsed: 250.710 s. Mean Reward: 0.000. Mean Group Reward: 0.113. Training. ELO: 1193.166.\n",
            "[INFO] SoccerTwos. Step: 120000. Time Elapsed: 282.847 s. Mean Reward: 0.000. Mean Group Reward: -0.072. Training. ELO: 1192.462.\n",
            "[INFO] SoccerTwos. Step: 130000. Time Elapsed: 302.005 s. Mean Reward: 0.000. Mean Group Reward: -0.100. Training.\n",
            "[INFO] SoccerTwos. Step: 140000. Time Elapsed: 320.007 s. Mean Reward: 0.000. Mean Group Reward: -0.118. Training. ELO: 1193.205.\n",
            "[INFO] SoccerTwos. Step: 150000. Time Elapsed: 346.608 s. Mean Reward: 0.000. Mean Group Reward: -0.045. Training. ELO: 1193.583.\n",
            "[INFO] SoccerTwos. Step: 160000. Time Elapsed: 365.861 s. Mean Reward: 0.000. Mean Group Reward: -0.168. Training. ELO: 1194.709.\n",
            "[INFO] SoccerTwos. Step: 170000. Time Elapsed: 392.874 s. Mean Reward: 0.000. Mean Group Reward: -0.043. Training. ELO: 1194.580.\n",
            "[INFO] SoccerTwos. Step: 180000. Time Elapsed: 411.937 s. Mean Reward: 0.000. Mean Group Reward: -0.171. Training. ELO: 1194.325.\n",
            "[INFO] SoccerTwos. Step: 190000. Time Elapsed: 429.905 s. Mean Reward: 0.000. Mean Group Reward: -0.093. Training. ELO: 1194.449.\n",
            "[INFO] SoccerTwos. Step: 200000. Time Elapsed: 452.562 s. Mean Reward: 0.000. Mean Group Reward: -0.119. Training. ELO: 1194.059.\n",
            "[INFO] SoccerTwos. Step: 210000. Time Elapsed: 480.916 s. Mean Reward: 0.000. Mean Group Reward: -0.082. Training. ELO: 1193.231.\n",
            "[INFO] SoccerTwos. Step: 220000. Time Elapsed: 507.754 s. Mean Reward: 0.000. Mean Group Reward: -0.006. Training. ELO: 1192.902.\n",
            "[INFO] SoccerTwos. Step: 230000. Time Elapsed: 525.382 s. Mean Reward: 0.000. Mean Group Reward: -0.014. Training. ELO: 1193.237.\n",
            "[INFO] SoccerTwos. Step: 240000. Time Elapsed: 549.194 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training.\n",
            "[INFO] SoccerTwos. Step: 250000. Time Elapsed: 568.623 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 260000. Time Elapsed: 591.330 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 270000. Time Elapsed: 612.913 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 280000. Time Elapsed: 630.080 s. Mean Reward: 0.000. Mean Group Reward: -0.081. Training. ELO: 1192.862.\n",
            "[INFO] SoccerTwos. Step: 290000. Time Elapsed: 661.937 s. Mean Reward: 0.000. Mean Group Reward: -0.364. Training. ELO: 1191.866.\n",
            "[INFO] SoccerTwos. Step: 300000. Time Elapsed: 672.774 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1190.528.\n",
            "[INFO] SoccerTwos. Step: 310000. Time Elapsed: 700.584 s. Mean Reward: 0.000. Mean Group Reward: -0.101. Training. ELO: 1190.289.\n",
            "[INFO] SoccerTwos. Step: 320000. Time Elapsed: 724.717 s. Mean Reward: 0.000. Mean Group Reward: 0.078. Training. ELO: 1189.366.\n",
            "[INFO] SoccerTwos. Step: 330000. Time Elapsed: 751.675 s. Mean Reward: 0.000. Mean Group Reward: -0.159. Training. ELO: 1188.825.\n",
            "[INFO] SoccerTwos. Step: 340000. Time Elapsed: 767.082 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 350000. Time Elapsed: 791.055 s. Mean Reward: 0.000. Mean Group Reward: 0.225. Training. ELO: 1190.849.\n",
            "[INFO] SoccerTwos. Step: 360000. Time Elapsed: 816.085 s. Mean Reward: 0.000. Mean Group Reward: -0.163. Training. ELO: 1191.726.\n",
            "[INFO] SoccerTwos. Step: 370000. Time Elapsed: 836.258 s. Mean Reward: 0.000. Mean Group Reward: -0.168. Training. ELO: 1191.597.\n",
            "[INFO] SoccerTwos. Step: 380000. Time Elapsed: 854.977 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 390000. Time Elapsed: 870.317 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1191.346.\n",
            "[INFO] SoccerTwos. Step: 400000. Time Elapsed: 891.268 s. Mean Reward: 0.000. Mean Group Reward: -0.199. Training. ELO: 1191.696.\n",
            "[INFO] SoccerTwos. Step: 410000. Time Elapsed: 918.858 s. Mean Reward: 0.000. Mean Group Reward: -0.265. Training. ELO: 1191.367.\n",
            "[INFO] SoccerTwos. Step: 420000. Time Elapsed: 951.027 s. Mean Reward: 0.000. Mean Group Reward: -0.462. Training. ELO: 1190.208.\n",
            "[INFO] SoccerTwos. Step: 430000. Time Elapsed: 964.318 s. Mean Reward: 0.000. Mean Group Reward: 0.089. Training. ELO: 1189.378.\n",
            "[INFO] SoccerTwos. Step: 440000. Time Elapsed: 988.966 s. Mean Reward: 0.000. Mean Group Reward: -0.500. Training. ELO: 1188.559.\n",
            "[INFO] SoccerTwos. Step: 450000. Time Elapsed: 1004.139 s. Mean Reward: 0.000. Mean Group Reward: 0.157. Training. ELO: 1187.415.\n",
            "[INFO] SoccerTwos. Step: 460000. Time Elapsed: 1027.728 s. Mean Reward: 0.000. Mean Group Reward: 0.146. Training. ELO: 1188.306.\n",
            "[INFO] SoccerTwos. Step: 470000. Time Elapsed: 1051.130 s. Mean Reward: 0.000. Mean Group Reward: -0.216. Training. ELO: 1187.571.\n",
            "[INFO] SoccerTwos. Step: 480000. Time Elapsed: 1073.423 s. Mean Reward: 0.000. Mean Group Reward: -0.100. Training.\n",
            "[INFO] SoccerTwos. Step: 490000. Time Elapsed: 1092.473 s. Mean Reward: 0.000. Mean Group Reward: 0.035. Training. ELO: 1188.239.\n",
            "[INFO] SoccerTwos. Step: 500000. Time Elapsed: 1112.529 s. Mean Reward: 0.000. Mean Group Reward: 0.126. Training. ELO: 1188.502.\n",
            "[INFO] Exported results/SoccerTwos1/SoccerTwos/SoccerTwos-499420.onnx\n",
            "[INFO] SoccerTwos. Step: 510000. Time Elapsed: 1138.594 s. Mean Reward: 0.000. Mean Group Reward: 0.044. Training. ELO: 1188.502.\n",
            "[INFO] SoccerTwos. Step: 520000. Time Elapsed: 1157.195 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 530000. Time Elapsed: 1184.518 s. Mean Reward: 0.000. Mean Group Reward: -0.102. Training. ELO: 1189.015.\n",
            "[INFO] SoccerTwos. Step: 540000. Time Elapsed: 1195.775 s. Mean Reward: 0.000. Mean Group Reward: 0.050. Training. ELO: 1188.529.\n",
            "[INFO] SoccerTwos. Step: 550000. Time Elapsed: 1222.820 s. Mean Reward: 0.000. Mean Group Reward: 0.238. Training. ELO: 1188.529.\n",
            "[INFO] SoccerTwos. Step: 560000. Time Elapsed: 1235.392 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 570000. Time Elapsed: 1269.950 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1187.780.\n",
            "[INFO] SoccerTwos. Step: 580000. Time Elapsed: 1287.841 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1187.531.\n",
            "[INFO] SoccerTwos. Step: 590000. Time Elapsed: 1307.466 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 600000. Time Elapsed: 1334.331 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 610000. Time Elapsed: 1371.830 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 620000. Time Elapsed: 1389.776 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1187.531.\n",
            "[INFO] SoccerTwos. Step: 630000. Time Elapsed: 1403.368 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1186.802.\n",
            "[INFO] SoccerTwos. Step: 640000. Time Elapsed: 1436.181 s. Mean Reward: 0.000. Mean Group Reward: 0.049. Training. ELO: 1187.325.\n",
            "[INFO] SoccerTwos. Step: 650000. Time Elapsed: 1456.015 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 660000. Time Elapsed: 1474.487 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 670000. Time Elapsed: 1493.433 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1186.831.\n",
            "[INFO] SoccerTwos. Step: 680000. Time Elapsed: 1522.334 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 690000. Time Elapsed: 1537.141 s. Mean Reward: 0.000. Mean Group Reward: -0.333. Training. ELO: 1186.581.\n",
            "[INFO] SoccerTwos. Step: 700000. Time Elapsed: 1560.118 s. Mean Reward: 0.000. Mean Group Reward: 0.105. Training. ELO: 1187.339.\n",
            "[INFO] SoccerTwos. Step: 710000. Time Elapsed: 1575.218 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 720000. Time Elapsed: 1609.830 s. Mean Reward: 0.000. Mean Group Reward: -0.226. Training. ELO: 1187.591.\n",
            "[INFO] SoccerTwos. Step: 730000. Time Elapsed: 1623.224 s. Mean Reward: 0.000. Mean Group Reward: 0.059. Training. ELO: 1188.342.\n",
            "[INFO] SoccerTwos. Step: 740000. Time Elapsed: 1648.714 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 750000. Time Elapsed: 1661.477 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 760000. Time Elapsed: 1687.495 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 770000. Time Elapsed: 1713.338 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 780000. Time Elapsed: 1726.849 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 790000. Time Elapsed: 1751.961 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 800000. Time Elapsed: 1772.905 s. Mean Reward: 0.000. Mean Group Reward: 0.022. Training. ELO: 1188.592.\n",
            "[INFO] SoccerTwos. Step: 810000. Time Elapsed: 1812.167 s. Mean Reward: 0.000. Mean Group Reward: 0.012. Training.\n",
            "[INFO] SoccerTwos. Step: 820000. Time Elapsed: 1828.308 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 830000. Time Elapsed: 1854.082 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 840000. Time Elapsed: 1876.008 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 850000. Time Elapsed: 1900.281 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 860000. Time Elapsed: 1919.131 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 870000. Time Elapsed: 1938.502 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 880000. Time Elapsed: 1965.001 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 890000. Time Elapsed: 1983.200 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 900000. Time Elapsed: 2006.378 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 910000. Time Elapsed: 2030.632 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1188.966.\n",
            "[INFO] SoccerTwos. Step: 920000. Time Elapsed: 2055.278 s. Mean Reward: 0.000. Mean Group Reward: 0.112. Training.\n",
            "[INFO] SoccerTwos. Step: 930000. Time Elapsed: 2073.030 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 940000. Time Elapsed: 2098.975 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 950000. Time Elapsed: 2112.794 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 960000. Time Elapsed: 2145.909 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 970000. Time Elapsed: 2164.227 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 980000. Time Elapsed: 2186.146 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 990000. Time Elapsed: 2209.575 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 1000000. Time Elapsed: 2228.070 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] Exported results/SoccerTwos1/SoccerTwos/SoccerTwos-999724.onnx\n",
            "[INFO] SoccerTwos. Step: 1010000. Time Elapsed: 2268.485 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 1020000. Time Elapsed: 2284.835 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 1030000. Time Elapsed: 2312.353 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 1040000. Time Elapsed: 2330.629 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 1050000. Time Elapsed: 2354.408 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 1060000. Time Elapsed: 2375.143 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 1070000. Time Elapsed: 2394.596 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] Learning was interrupted. Please wait while the graph is generated.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/mlagents-learn\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('mlagents', 'console_scripts', 'mlagents-learn')())\n",
            "  File \"/content/ml-agents/ml-agents/mlagents/trainers/learn.py\", line 270, in main\n",
            "    run_cli(parse_command_line())\n",
            "  File \"/content/ml-agents/ml-agents/mlagents/trainers/learn.py\", line 266, in run_cli\n",
            "    run_training(run_seed, options, num_areas)\n",
            "  File \"/content/ml-agents/ml-agents/mlagents/trainers/learn.py\", line 138, in run_training\n",
            "    tc.start_learning(env_manager)\n",
            "  File \"/content/ml-agents/ml-agents-envs/mlagents_envs/timers.py\", line 305, in wrapped\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/ml-agents/ml-agents/mlagents/trainers/trainer_controller.py\", line 200, in start_learning\n",
            "    self._save_models()\n",
            "  File \"/content/ml-agents/ml-agents-envs/mlagents_envs/timers.py\", line 305, in wrapped\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/ml-agents/ml-agents/mlagents/trainers/trainer_controller.py\", line 80, in _save_models\n",
            "    self.trainers[brain_name].save_model()\n",
            "  File \"/content/ml-agents/ml-agents/mlagents/trainers/ghost/trainer.py\", line 334, in save_model\n",
            "    self.trainer.save_model()\n",
            "  File \"/content/ml-agents/ml-agents/mlagents/trainers/trainer/rl_trainer.py\", line 172, in save_model\n",
            "    model_checkpoint = self._checkpoint()\n",
            "  File \"/content/ml-agents/ml-agents-envs/mlagents_envs/timers.py\", line 305, in wrapped\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/ml-agents/ml-agents/mlagents/trainers/trainer/rl_trainer.py\", line 144, in _checkpoint\n",
            "    export_path, auxillary_paths = self.model_saver.save_checkpoint(\n",
            "  File \"/content/ml-agents/ml-agents/mlagents/trainers/model_saver/torch_model_saver.py\", line 53, in save_checkpoint\n",
            "    state_dict = {\n",
            "  File \"/content/ml-agents/ml-agents/mlagents/trainers/model_saver/torch_model_saver.py\", line 54, in <dictcomp>\n",
            "    name: module.state_dict() for name, module in self.modules.items()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2216, in state_dict\n",
            "    module.state_dict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2216, in state_dict\n",
            "    module.state_dict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2216, in state_dict\n",
            "    module.state_dict(\n",
            "  [Previous line repeated 1 more time]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2211, in state_dict\n",
            "    for hook in self._state_dict_pre_hooks.values():\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "5zInAJF8sjmH",
        "outputId": "7612069d-9858-410d-c69a-ff520a335a51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "The token `deep-rl-course-fronzenlake` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `deep-rl-course-fronzenlake`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "FDiqe883GeON",
        "outputId": "5c6feb4a-897b-4909-944d-e6903c06bdc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ml-agents'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-push-to-hf  --run-id=\"SoccerTwos\" --local-dir=\"./results/SoccerTwos1\" --repo-id=\"sanjay-906/poca-SoccerTwos\" --commit-message=\"First Push\""
      ],
      "metadata": {
        "id": "38jEZ62DF-NP",
        "outputId": "cf2b212c-c1fb-4b78-a76d-ae1f3973bd7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] This function will create a model card and upload your SoccerTwos into HuggingFace Hub. This is a work in progress: If you encounter a bug, please send open an issue\n",
            "[INFO] Pushing repo SoccerTwos to the Hugging Face Hub\n",
            "SoccerTwos.onnx:   0% 0.00/1.77M [00:00<?, ?B/s]\n",
            "Upload 2 LFS files:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "SoccerTwos.pt:   0% 0.00/28.4M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos.onnx:  93% 1.64M/1.77M [00:00<00:00, 9.13MB/s]\n",
            "\n",
            "SoccerTwos.pt:  11% 3.01M/28.4M [00:00<00:09, 2.69MB/s]\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos.pt:  18% 5.01M/28.4M [00:01<00:04, 4.77MB/s]\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos.pt:  21% 6.11M/28.4M [00:01<00:03, 5.63MB/s]\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos.pt:  26% 7.27M/28.4M [00:01<00:03, 6.63MB/s]\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos.pt:  32% 8.96M/28.4M [00:01<00:02, 8.56MB/s]\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos.onnx: 100% 1.77M/1.77M [00:01<00:00, 1.12MB/s]\n",
            "\n",
            "Upload 2 LFS files:  50% 1/2 [00:01<00:01,  1.93s/it]\u001b[A\n",
            "\n",
            "SoccerTwos.pt:  56% 16.0M/28.4M [00:02<00:01, 7.29MB/s]\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos.pt:  76% 21.6M/28.4M [00:02<00:00, 12.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos.pt:  86% 24.6M/28.4M [00:02<00:00, 13.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos.pt: 100% 28.4M/28.4M [00:04<00:00, 6.65MB/s]\n",
            "\n",
            "Upload 2 LFS files: 100% 2/2 [00:04<00:00,  2.32s/it]\n",
            "[INFO] Your model is pushed to the hub. You can view your model here: https://huggingface.co/sanjay-906/poca-SoccerTwos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5UX9alFhGo2z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}